{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da9e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gymnasium as gym\n",
    "\n",
    "# env = gym.make(\"CarRacing-v3\", render_mode=\"human\")\n",
    "# obs, info = env.reset()\n",
    "# done = False\n",
    "\n",
    "# while not done:\n",
    "#     obs, reward, done, trunc, info = env.step(env.action_space.sample())\n",
    "#     env.render()\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "661d086c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2cf75d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name ='CarRacing-v3'\n",
    "env = gym.make(environment_name, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1499ec3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], shape=(96, 96, 3), dtype=uint8),\n",
       " {})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b2e1be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1.  0.  0.], 1.0, (3,), float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "324bb97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (96, 96, 3), uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 5 \n",
    "for episode in range(1, episodes + 1):\n",
    "    obs, info = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    score = 0\n",
    "\n",
    "    while not (terminated or truncated):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "\n",
    "    print(f\"Episode: {episode} | Score: {score:.2f}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f80277d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e0e7a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4c98bcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training','Logs')\n",
    "model = PPO('CnnPolicy',env,verbose=1,tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85238401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_18\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 117  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 17   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008495262 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | -0.00875    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    std                  | 0.993       |\n",
      "|    value_loss           | 0.668       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 77          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009198856 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    std                  | 0.985       |\n",
      "|    value_loss           | 0.525       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009700954 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.19       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 0.398       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012371037 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.18       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0863      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    std                  | 0.974       |\n",
      "|    value_loss           | 0.37        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013394492 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.16       |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 0.549       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013809691 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.14       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0722      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 0.358       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 71         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 230        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01426424 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.12      |\n",
      "|    explained_variance   | 0.299      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.101      |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.0175    |\n",
      "|    std                  | 0.954      |\n",
      "|    value_loss           | 0.274      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014898673 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.12       |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0657      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    std                  | 0.955       |\n",
      "|    value_loss           | 0.337       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 71        |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 286       |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0180454 |\n",
      "|    clip_fraction        | 0.195     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -4.12     |\n",
      "|    explained_variance   | 0.337     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0406    |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -0.0224   |\n",
      "|    std                  | 0.951     |\n",
      "|    value_loss           | 0.309     |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f165c1eb0d0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "181b0cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('Training','Saved Models','PPO_Driving_Model_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e85c3abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "681de6b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model\n\u001b[1;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(environment_name, render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: env])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model\n",
    "env = gym.make(environment_name, render_mode=\"human\")\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c221a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name, render_mode=\"human\")\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3b1e1979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(ppo_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "786085ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(512.6073296554387), np.float64(115.14441263698131))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9cc357ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
