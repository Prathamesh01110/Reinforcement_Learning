{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b3e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c354f770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3: Error while finding module specification for 'atari_py.import_roms' (ModuleNotFoundError: No module named 'atari_py')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m atari_py.import_roms ./roms/ROMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68030953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ale-py in /home/illusion/.local/lib/python3.10/site-packages (0.11.1)\n",
      "Requirement already satisfied: numpy>1.20 in /home/illusion/.local/lib/python3.10/site-packages (from ale-py) (2.2.6)\n",
      "Requirement already satisfied: typing-extensions in /home/illusion/.local/lib/python3.10/site-packages (from ale-py) (4.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ale-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f55c19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], shape=(210, 160, 3), dtype=uint8),\n",
       " {'lives': 5, 'episode_frame_number': 0, 'frame_number': 0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import time\n",
    "import ale_py\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "env = gym.make('ALE/Breakout-v5',render_mode=\"human\")\n",
    "env.reset()\n",
    "# obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "# env.render()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "978fd4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61715d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6e9010a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1  Score: 2.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m     10\u001b[0m action \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()  \u001b[38;5;66;03m# Random action\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m     13\u001b[0m score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/core.py:327\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gymnasium/wrappers/common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ale_py/env.py:305\u001b[0m, in \u001b[0;36mAtariEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    303\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(frameskip):\n\u001b[0;32m--> 305\u001b[0m     reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43male\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m is_terminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_over(with_truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    308\u001b[0m is_truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_truncated()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "    obs, info = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()  # Random action\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        score += reward\n",
    "\n",
    "    print(f\"Episode: {episode}  Score: {score}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 5\n",
    "for episode in range(1,episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs , reward ,done, info = env.step(action)\n",
    "        score += reward\n",
    "    print('Episode:{} Score:{}',format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32d5a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.11.1+2750686)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS0AAAGbCAYAAACRcMaGAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAG3NJREFUeJzt3Xl0VPX9//HXTPYFEpAlLDF8gcpmLYo0FKvJD6RAKVTbioC0gCiKWI5at7YWiNZTEOvSRRA8gseaqhSr4lIVAaXg0q9UFgUXQBFUSghJgCyQzOf3h99MGWYCkzA3zFuej3NyDsxdPvdOJs+5c+cm43POOQGAEf6TvQEA0BhEC4ApRAuAKUQLgClEC4ApRAuAKUQLgClEC4ApRAuAKUQLMeHz+TRr1qyTvRlBEydOVJcuXaKad9asWfL5fE0ap7CwUIWFhU1aFk0Td9Havn27rr32Wp1xxhlKT09Xenq6evfurWnTpmnDhg0ne/OabNmyZSooKFC7du2Unp6url27avTo0frHP/4RnOfzzz/XrFmz9O6773qyDcXFxbrvvvs8WbcXfD6frr322pisq7KyUrNmzdKqVatisr7G6tKli3w+X8Sv6urqk7JNViWe7A040nPPPadLL71UiYmJuuyyy/Stb31Lfr9fW7Zs0VNPPaV58+Zp+/btysvLO9mb2ih33323brrpJhUUFOiXv/yl0tPT9fHHH2v58uV6/PHHNWzYMElfRauoqEhdunRR3759Y74dxcXF2rRpk6677rqYrzveLFy4UIFAIPj/yspKFRUVSVLYkdFtt92mW2+91fNt6tu3r37xi1+E3Z6cnOz52F8ncROtrVu3asyYMcrLy9Orr76qDh06hEyfM2eOHnjgAfn9cXdweEy1tbW64447NGTIEL388sth0//zn/94vg0HDx5URkaG5+PEk6SkpKjnTUxMVGKi9z8KnTp10vjx46Oev7KyUunp6R5ukU1xU4C77rpLBw8e1KJFi8KCJX31wJo+fbpyc3ODt23YsEETJ05U165dlZqaqpycHF1++eXau3dvyLL15yw+/PBDjR8/XllZWWrbtq1+85vfyDmnzz77TD/84Q/VsmVL5eTk6Pe//33Y+DU1NZo5c6a6d++ulJQU5ebm6uabb1ZNTc0x96ukpEQVFRU677zzIk5v166dJGnVqlXq37+/JGnSpEnBlw6LFy+WJK1evVqXXHKJTj/99OD4119/vaqqqkLWN3HiRGVmZmrr1q36/ve/rxYtWuiyyy5TYWGhnn/+eX366afBdR95zifa/aupqdH111+vtm3bqkWLFho1apR27tx5zPsgVlatWiWfz6cnn3xSd955pzp37qzU1FQNHjxYH3/8cci8R57T+uSTT9S2bVtJUlFRUXD/68/BRTqntWjRIg0aNEjt2rVTSkqKevfurXnz5nm2b4WFhTrzzDP1zjvv6IILLlB6erp+9atfSZKeeeYZjRgxQh07dlRKSoq6deumO+64Q3V1dRHXsWHDBhUUFCg9PV3du3fX3/72N0nSa6+9pvz8fKWlpalHjx5avnx52Hbs2rVLl19+udq3b6+UlBT16dNHDz/8sGf73RRxc6T13HPPqXv37srPz496mVdeeUXbtm3TpEmTlJOTo/fee08LFizQe++9pzfffDPsgXjppZeqV69emj17tp5//nn99re/VevWrfXggw9q0KBBmjNnjh577DHdeOON6t+/vy644AJJUiAQ0KhRo/TPf/5TU6ZMUa9evbRx40bde++9+vDDD/X00083uI3t2rVTWlqali1bpp///Odq3bp1xPl69eql22+/XTNmzNCUKVN0/vnnS5IGDhwoSVqyZIkqKys1depUnXbaaXr77bf1xz/+UTt37tSSJUtC1lVbW6uhQ4fqu9/9ru6++26lp6crJydH5eXl2rlzp+69915JUmZmZqP374orrtBf/vIXjRs3TgMHDtSKFSs0YsSIqL9nsTB79mz5/X7deOONKi8v11133aXLLrtMb731VsT527Ztq3nz5mnq1Km6+OKL9aMf/UiSdNZZZzU4xrx589SnTx+NGjVKiYmJWrZsma655hoFAgFNmzatSdt9+PBhlZSUhNxWf95Wkvbu3avhw4drzJgxGj9+vNq3by9JWrx4sTIzM3XDDTcoMzNTK1as0IwZM1RRUaG5c+eGrG/fvn36wQ9+oDFjxuiSSy7RvHnzNGbMGD322GO67rrrdPXVV2vcuHGaO3eufvKTn+izzz5TixYtJEm7d+/WgAEDgucS27ZtqxdffFGTJ09WRUVF/JxWcHGgvLzcSXIXXXRR2LR9+/a5PXv2BL8qKyuD0478d72//vWvTpJ7/fXXg7fNnDnTSXJTpkwJ3lZbW+s6d+7sfD6fmz17dsh4aWlpbsKECcHbHn30Uef3+93q1atDxpo/f76T5NasWXPM/ZsxY4aT5DIyMtzw4cPdnXfe6d55552w+f71r385SW7RokVh0yLt6+9+9zvn8/ncp59+GrxtwoQJTpK79dZbw+YfMWKEy8vLC7s92v179913nSR3zTXXhMw3btw4J8nNnDkz0u43mSQ3bdq04P9XrlzpJLlevXq5mpqa4O3333+/k+Q2btwYvG3ChAkh+7pnz54Gt7H+8XGkSPf30KFDXdeuXUNuKygocAUFBcfdl7y8PCcp7Kt+ewoKCpwkN3/+/LBlI23LVVdd5dLT0111dXXItkhyxcXFwdu2bNniJDm/3+/efPPN4O0vvfRS2GNt8uTJrkOHDq6kpCRkrDFjxrisrKyI23EyxMXLw4qKCkn/feY/UmFhodq2bRv8+vOf/xyclpaWFvx3dXW1SkpKNGDAAEnSunXrwtZ1xRVXBP+dkJCgc889V845TZ48OXh7dna2evTooW3btgVvW7JkiXr16qWePXuqpKQk+DVo0CBJ0sqVK4+5f0VFRSouLtbZZ5+tl156Sb/+9a/Vr18/nXPOOdq8efMxl420rwcPHlRJSYkGDhwo55z+/e9/h80/derUqNbbmP174YUXJEnTp08PWb65n4EnTZoUcvK6/qj0yO/ZiTry/i4vL1dJSYkKCgq0bds2lZeXN2md+fn5euWVV0K+fvaznwWnp6SkaNKkScfclv3796ukpETnn3++KisrtWXLlpB5MzMzNWbMmOD/e/TooezsbPXq1SvkVUz9v+vvM+ecli5dqpEjR8o5F/I4GDp0qMrLyyP+TJ0McfHysP7w9MCBA2HTHnzwQe3fv1+7d+8OO4lZWlqqoqIiPf7442EntCM9sE4//fSQ/2dlZSk1NVVt2rQJu/3I82IfffSRNm/eHDwvcrRoTqaPHTtWY8eOVUVFhd566y0tXrxYxcXFGjlypDZt2qTU1NRjLr9jxw7NmDFDzz77rPbt2xcy7eh9TUxMVOfOnY+7TfWi3b9PP/1Ufr9f3bp1C5neo0ePqMb58ssvQ/6flZUV8gMZraO/j61atZKksPvlRKxZs0YzZ87UG2+8ocrKypBp5eXlysrKavQ627RpowsvvLDB6Z06dYr4TuJ7772n2267TStWrAg+wR+5LUfq3Llz2GmRrKyskHPB9bdJ/73P9uzZo7KyMi1YsEALFiyIuH3N8aZRNOIiWllZWerQoYM2bdoUNq3+GeGTTz4JmzZ69GitXbtWN910k/r27avMzEwFAgENGzYs5O3uegkJCVHdJn31zFMvEAjom9/8pu65556I8x79gDiWli1basiQIRoyZIiSkpL0yCOP6K233lJBQUGDy9TV1WnIkCEqLS3VLbfcop49eyojI0O7du3SxIkTw/Y1JSWlUe+yxnL/juXoN1gWLVqkiRMnNno90XzPTsTWrVs1ePBg9ezZU/fcc49yc3OVnJysF154Qffee2/Ex1YsRAp4WVmZCgoK1LJlS91+++3q1q2bUlNTtW7dOt1yyy1h29LQfXO8+6x+PePHj9eECRMiznusc4DNKS6iJUkjRozQQw89pLffflvf/va3jzv/vn379Oqrr6qoqEgzZswI3v7RRx/FfNu6deum9evXa/DgwU2+cjqSc889V4888oi++OILSWpw3Rs3btSHH36oRx55JOTlxCuvvNKo8Rpaf7T7l5eXp0AgoK1bt4YcXX3wwQdRjX/09vbp0yeq5WKhMd+3ZcuWqaamRs8++2zIUd3xTgN4YdWqVdq7d6+eeuqp4BtD0lcXYcdS/bvBdXV1xzwajAdxcU5Lkm6++Walp6fr8ssv1+7du8OmH/0sWv/McfTtXlzxPXr0aO3atUsLFy4Mm1ZVVaWDBw82uGxlZaXeeOONiNNefPFFSf99eVV/LVVZWVnIfJH21Tmn+++/P/qd+L/1R3rZHO3+DR8+XJL0hz/8IWSeaO/zCy+8MOQr0qUtXql/h+7o+zaSSPd3eXm5Fi1a5Mm2NXZbDh06pAceeCDm4/z4xz/W0qVLI77i2bNnT0zHOxFxc6T1jW98Q8XFxRo7dqx69OgRvCLeOaft27eruLhYfr8/eK6mZcuWuuCCC3TXXXfp8OHD6tSpk15++eWYPwNJ0k9/+lM9+eSTuvrqq7Vy5Uqdd955qqur05YtW/Tkk0/qpZde0rnnnhtx2crKSg0cOFADBgzQsGHDlJubq7KyMj399NNavXq1LrroIp199tmSvjriyc7O1vz589WiRQtlZGQoPz9fPXv2VLdu3XTjjTdq165datmypZYuXdroczj9+vXTE088oRtuuEH9+/dXZmamRo4cGfX+9e3bV2PHjtUDDzyg8vJyDRw4UK+++mrYNVLxKC0tTb1799YTTzyhM844Q61bt9aZZ56pM888M2ze733ve0pOTtbIkSN11VVX6cCBA1q4cKHatWsXPCpuLgMHDlSrVq00YcIETZ8+XT6fT48++mjMXgofafbs2Vq5cqXy8/N15ZVXqnfv3iotLdW6deu0fPlylZaWxnzMJjkJ71ge08cff+ymTp3qunfv7lJTU11aWprr2bOnu/rqq927774bMu/OnTvdxRdf7LKzs11WVpa75JJL3Oeffx721nb9W9p79uwJWX7ChAkuIyMjbBsKCgpcnz59Qm47dOiQmzNnjuvTp49LSUlxrVq1cv369XNFRUWuvLy8wf05fPiwW7hwobvoootcXl6eS0lJcenp6e7ss892c+fODXnr3jnnnnnmGde7d2+XmJgY8pb0+++/7y688EKXmZnp2rRp46688kq3fv36sLetG9on55w7cOCAGzdunMvOznaSQi4JiHb/qqqq3PTp091pp53mMjIy3MiRI91nn33WrJc8LFmyJGS+7du3R7wfjr68Y+3ata5fv34uOTk5ZHsjXfLw7LPPurPOOsulpqa6Ll26uDlz5riHH37YSXLbt28PzteYSx5GjBjR4PRIj7l6a9ascQMGDHBpaWmuY8eO7uabbw5esrBy5crjrqOhsY++f51zbvfu3W7atGkuNzfXJSUluZycHDd48GC3YMGC4+5jc/E5x+ceArAjbs5pAUA0iBYAU4gWAFOIFgBTiBYAU4gWAFOivrg0lr++AgCRRHMFFkdaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEyJmz8CGM9at26t7OzsmK6zvLw87ENl62VmZgY/xDVWqqqqGvwDdikpKerYsWNMr8Wrra3Vrl27wj5Q9GTJycmJ+ac179mzR/v374/pOr2QkZER/AzFo1VWVoZ94Ei8I1pR+M53vnPMD55oirVr1zb4Ia89evTQpZdeGtPxtm7dqoceeihiRNq1a6fJkydH/CSYpiorK9Of/vSnsE+PORn8fr9GjBgR9acGRWvp0qUNfkBsPOnatavGjx8f8Ulp8+bNWrx4sSd/CdUrRCsKfr9fiYmxvauO9Wk5Pp9PCQkJMT3yOd54iYmJMd3HWG//iUpISGjW72E8qX/8Rvp+NPQpPfGMaJ2g4z1DxfoHN97G82LM5mbpKANE64Rt2LBBGzZsiDitT58+Ouecc2I63o4dO/T6669HnNapUycVFhbG9AigrKxML7/8sg4dOhQ2rWXLlho6dOhxP2g2njnn9Prrr2vHjh2NXrYpy+DEEa0T9MUXX0T8WHpJys7Ojnm09u3b1+B41dXVKiwsjOl4VVVVWr9+vaqrq8OmtWnTRoMHD47peCfDtm3btHHjxpO9GYiSjRflAPB/ONLCKa9NmzbKzc1t9HKlpaXH/KBeeINo4ZQ3bNgwBQKBRi/397//XW+//bYHW4RjIVo4pfl8PiUlJTVpWYuXC3wdEC2cMppyaYP1yzm+jogWvvYCgYBee+01rV+/vtHL5ufnq0uXLrHfKDQZ0cIp4YMPPmjSct26dSNacYZLHgCYwpHWCcrMzFROTk7EaS1atIj5eGlpaerQoUPE8zOtWrWK+XhJSUlq3769ampqIo5n5ffvWrVqpZSUlEYvl5aW5sHW4EQQrROUn5+vfv36RZwW61/QlaTu3bvr2muvjTjN7/fH/MTxaaedpilTpkSc5vP5mhSC5ub3+zVq1CidccYZjV62qe8swjtE6wQlJSU16wM7ISGhWZ/9/X7/1+JoIyUl5WuxH+CcFgBjONKKwqZNm1RWVhbTdX7++ecNTtuxY0eDfyCwqcrKyhq86nvfvn1atmxZTM9P1dTUqKqqKmbrOxGBQEBr167V5s2bY7re7du3x3R9Xtm1a1eDj6fS0lJzf5rH56LcYi6yA+C1aHLEy0MApkT98rBNmzZebgcARCXqaE2fPt3L7QCAqEQdrczMTC+3AwCiwjktAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmEC0AphAtAKYQLQCmRP25h03lnPN6CABxxufzebZuT6N16NAhrVixQuXl5V4OAyCOZGVladCgQUpOTvZk/Z5Gq7a2VuvXr9fu3bu9HAZAHOnQoYMKCgo8Wz/ntACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJhCtACYQrQAmEK0AJiS6OXKUxMSNKFrVx1u1crLYQDEkaTWrZWSkODZ+j2NVpLfr2EdOyo9K8vLYQDEkYOZmdrk86nOo/Xz8hCAKUQLgClEC4ApRAuAKUQLgClEC4ApRAuAKUQLgCmeXlz61QhOLjHg+TAA4kSCk3zerd7baPmdAu2r5A4d9HQYAPHDJScajpb0VXUTnefDAIgTHr+y4pwWAFOIFgBTiBYAU4gWAFOIFgBTiBYAU4gWAFOIFgBTvL241CfVJNXK5zvs6TAA4kdNUp2cz7sLyj2NlpNTdcphuUSiBZwqahK8/Xnn5SEAU4gWAFOIFgBTiBYAU4gWAFOIFgBTiBYAU4gWAFM8/3PLzidPr44FEF+cx4dC3l4R75cOdqxVjb/Wy2EAxJHaulq5Ku/W7/nvHtYlO/n4YAvglFFX66RqSR792HNOC4ApRAuAKUQLgClEC4ApRAuAKUQLgClEC4ApRAuAKZ5eXBqQT18qVc6leTkMgDjic6lKkeTzaP2eRqtWPq0LtNIBf5KXwwCII5muhfrLJ69+6r3/hWlJ3jUXwKmGc1oATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATPH8Oi3JJ+e4Tgs4dXj78+5ttGqTVbduuGprEjwdBkD8qEupk/6nQkrw5o/EexutgF+B3f8jdzDd02EAxI9A5kEpb5OUUOfJ+jmnBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFE8vLnUuoIMHtqqigivigVOFX3VyzpsLSyWvP9iitlKbN96nL3fv9nIYAHGkQ06O/t/5UySlerJ+j39h2qmurlqBumpvhwEQNwKBGtV/pI0XOKcFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwBSiBcAUogXAFKIFwJTEaGes8gUavfJqv5PzNXoxIGYyEhOVkRj1w/yEVdfVqeLw4WYbLx75AgEl19Qo2efND3/U3801LaoavfLDCVWq9LtGLwfEysW5uRqdl9ds463+z3809/33m228eJRaVaU+//u/ykhK8mT9UUerugnxOexzciJaOHkyEhPVLjW12cZr6dEPqiX1R1opgca/OosG57QAmEK0AJhCtACYQrQAmNJ87wUDJ0FVXZ1Ka2qabbwDtbXNNtapimjha+3vO3Zo+RdfNNt4VXV1zTbWqYpo4Wttf22t9nP087XCOS0ApnCkBSCmyg4f1t927FCKv/HHRPlRzBN1tJzjynYAx7e3pkbzP/qoScveF8U8PhdljXIGnNXoDQjU1qn0/a2qq2q+d28A2BVNjqKOls+j39gGgHrR5IgT8QBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATCFaAEwhWgBMIVoATOETpgGYwpEWAFOIFgBTiBYAU4gWAFOIFgBTiBYAU4gWAFOIFgBTiBYAU/4/Gc4hytrqlyUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game running! Close window or press Ctrl+C to stop.\n",
      "Episode:1 Score:3.0\n",
      "Episode:2 Score:2.0\n",
      "Episode:3 Score:3.0\n",
      "Episode:4 Score:2.0\n",
      "Episode:5 Score:2.0\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import pygame\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Register environments\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "# Create environment\n",
    "env = gym.make(\"ALE/Breakout-v5\", render_mode=\"rgb_array\")\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Show initial frame with matplotlib\n",
    "img = env.render()\n",
    "plt.imshow(img)\n",
    "plt.title(\"Game Started - Initial Frame\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Initialize pygame window\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode((img.shape[1], img.shape[0]))\n",
    "pygame.display.set_caption(\"Breakout Game\")\n",
    "\n",
    "print(\"Game running! Close window or press Ctrl+C to stop.\")\n",
    "\n",
    "episodes = 5\n",
    "\n",
    "try:\n",
    "    for episode in range(1, episodes + 1):\n",
    "        obs, info = env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        \n",
    "        while not done:\n",
    "            # Handle window close\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    raise KeyboardInterrupt\n",
    "            \n",
    "            # Game step\n",
    "            action = env.action_space.sample()\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            score += reward\n",
    "            \n",
    "            # Display frame\n",
    "            rgb_array = env.render()\n",
    "            surf = pygame.surfarray.make_surface(rgb_array.swapaxes(0, 1))\n",
    "            screen.blit(surf, (0, 0))\n",
    "            pygame.display.flip()\n",
    "            \n",
    "            time.sleep(0.05)\n",
    "        \n",
    "        print('Episode:{} Score:{}'.format(episode, score))\n",
    "        time.sleep(1)  # Pause between episodes\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "finally:\n",
    "    pygame.quit()\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc41c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/illusion/.local/lib/python3.10/site-packages/gymnasium/envs/registration.py:519: DeprecationWarning: \u001b[33mWARN: The environment Breakout-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = make_atari_env(\"Breakout-v0\",n_envs=4, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df638c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]],\n",
       "\n",
       "\n",
       "       [[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]]], shape=(4, 84, 84, 4), dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d0701a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], shape=(420, 320, 3), dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c7f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training','Logs')\n",
    "model = A2C('CnnPolicy',env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156e9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 275      |\n",
      "|    ep_rew_mean        | 1.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 261      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.0513   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.131    |\n",
      "|    value_loss         | 0.153    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 283      |\n",
      "|    ep_rew_mean        | 1.64     |\n",
      "| time/                 |          |\n",
      "|    fps                | 261      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.377    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 0.00144  |\n",
      "|    value_loss         | 0.0194   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 278      |\n",
      "|    ep_rew_mean        | 1.56     |\n",
      "| time/                 |          |\n",
      "|    fps                | 261      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.471    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 0.333    |\n",
      "|    value_loss         | 0.218    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 283      |\n",
      "|    ep_rew_mean        | 1.63     |\n",
      "| time/                 |          |\n",
      "|    fps                | 263      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 30       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.34    |\n",
      "|    explained_variance | 0.75     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.131   |\n",
      "|    value_loss         | 0.103    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 293      |\n",
      "|    ep_rew_mean        | 1.79     |\n",
      "| time/                 |          |\n",
      "|    fps                | 269      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | 0.823    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.11    |\n",
      "|    value_loss         | 0.0516   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 305      |\n",
      "|    ep_rew_mean        | 2.02     |\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0.67     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.362    |\n",
      "|    value_loss         | 0.207    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 316      |\n",
      "|    ep_rew_mean        | 2.23     |\n",
      "| time/                 |          |\n",
      "|    fps                | 272      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 51       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.856   |\n",
      "|    explained_variance | 0.884    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.0197   |\n",
      "|    value_loss         | 0.0148   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 308      |\n",
      "|    ep_rew_mean        | 2.11     |\n",
      "| time/                 |          |\n",
      "|    fps                | 273      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 58       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.505   |\n",
      "|    explained_variance | 0.385    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.0161  |\n",
      "|    value_loss         | 0.000774 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 314      |\n",
      "|    ep_rew_mean        | 2.16     |\n",
      "| time/                 |          |\n",
      "|    fps                | 275      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.743   |\n",
      "|    explained_variance | 0.974    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.00857  |\n",
      "|    value_loss         | 0.0187   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 315      |\n",
      "|    ep_rew_mean        | 2.18     |\n",
      "| time/                 |          |\n",
      "|    fps                | 276      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | -75.5    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.0187  |\n",
      "|    value_loss         | 0.0011   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 320      |\n",
      "|    ep_rew_mean        | 2.26     |\n",
      "| time/                 |          |\n",
      "|    fps                | 277      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.755   |\n",
      "|    explained_variance | 0.984    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.0266   |\n",
      "|    value_loss         | 0.00662  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 325      |\n",
      "|    ep_rew_mean        | 2.38     |\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.15    |\n",
      "|    explained_variance | 0.97     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.0456  |\n",
      "|    value_loss         | 0.00993  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 326      |\n",
      "|    ep_rew_mean        | 2.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0.796    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.161   |\n",
      "|    value_loss         | 0.097    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 342      |\n",
      "|    ep_rew_mean        | 2.76     |\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 100      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.17    |\n",
      "|    explained_variance | 0.966    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.0632  |\n",
      "|    value_loss         | 0.0106   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 354      |\n",
      "|    ep_rew_mean        | 3.06     |\n",
      "| time/                 |          |\n",
      "|    fps                | 278      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 107      |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.02    |\n",
      "|    explained_variance | 0.245    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.281   |\n",
      "|    value_loss         | 0.265    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 372      |\n",
      "|    ep_rew_mean        | 3.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 279      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 114      |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.922   |\n",
      "|    explained_variance | 0.886    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.041    |\n",
      "|    value_loss         | 0.0252   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 383      |\n",
      "|    ep_rew_mean        | 3.72     |\n",
      "| time/                 |          |\n",
      "|    fps                | 280      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 121      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.803   |\n",
      "|    explained_variance | 0.976    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -0.107   |\n",
      "|    value_loss         | 0.0268   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 406      |\n",
      "|    ep_rew_mean        | 4.18     |\n",
      "| time/                 |          |\n",
      "|    fps                | 280      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 36000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.902   |\n",
      "|    explained_variance | 0.86     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.1      |\n",
      "|    value_loss         | 0.0614   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 409      |\n",
      "|    ep_rew_mean        | 4.31     |\n",
      "| time/                 |          |\n",
      "|    fps                | 281      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 135      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.656   |\n",
      "|    explained_variance | -0.964   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.19     |\n",
      "|    value_loss         | 0.186    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 414      |\n",
      "|    ep_rew_mean        | 4.41     |\n",
      "| time/                 |          |\n",
      "|    fps                | 280      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 142      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.605   |\n",
      "|    explained_variance | 0.897    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | -0.0896  |\n",
      "|    value_loss         | 0.0654   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 428      |\n",
      "|    ep_rew_mean        | 4.73     |\n",
      "| time/                 |          |\n",
      "|    fps                | 281      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 149      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.461   |\n",
      "|    explained_variance | 0.903    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | -0.0351  |\n",
      "|    value_loss         | 0.0889   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 438      |\n",
      "|    ep_rew_mean        | 4.98     |\n",
      "| time/                 |          |\n",
      "|    fps                | 281      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 156      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.511   |\n",
      "|    explained_variance | 0.916    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.00637  |\n",
      "|    value_loss         | 0.071    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 447      |\n",
      "|    ep_rew_mean        | 5.22     |\n",
      "| time/                 |          |\n",
      "|    fps                | 281      |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.04    |\n",
      "|    explained_variance | 0.797    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.142   |\n",
      "|    value_loss         | 0.0957   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 452      |\n",
      "|    ep_rew_mean        | 5.3      |\n",
      "| time/                 |          |\n",
      "|    fps                | 283      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 169      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.2     |\n",
      "|    explained_variance | 0.86     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.00514  |\n",
      "|    value_loss         | 0.0471   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 458      |\n",
      "|    ep_rew_mean        | 5.46     |\n",
      "| time/                 |          |\n",
      "|    fps                | 284      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.11    |\n",
      "|    explained_variance | 0.915    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -0.143   |\n",
      "|    value_loss         | 0.067    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 442      |\n",
      "|    ep_rew_mean        | 5.1      |\n",
      "| time/                 |          |\n",
      "|    fps                | 285      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 182      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.722   |\n",
      "|    explained_variance | 0.978    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.0641  |\n",
      "|    value_loss         | 0.0355   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 451      |\n",
      "|    ep_rew_mean        | 5.33     |\n",
      "| time/                 |          |\n",
      "|    fps                | 285      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 189      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.899   |\n",
      "|    explained_variance | 0.295    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.111    |\n",
      "|    value_loss         | 0.179    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 451      |\n",
      "|    ep_rew_mean        | 5.39     |\n",
      "| time/                 |          |\n",
      "|    fps                | 285      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 195      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.611   |\n",
      "|    explained_variance | 0.976    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.0132   |\n",
      "|    value_loss         | 0.0665   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 458      |\n",
      "|    ep_rew_mean        | 5.52     |\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 202      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.947   |\n",
      "|    explained_variance | 0.146    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | -0.00304 |\n",
      "|    value_loss         | 0.274    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 469      |\n",
      "|    ep_rew_mean        | 5.74     |\n",
      "| time/                 |          |\n",
      "|    fps                | 286      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 209      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.553   |\n",
      "|    explained_variance | 0.664    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -0.0616  |\n",
      "|    value_loss         | 0.259    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 477      |\n",
      "|    ep_rew_mean        | 5.89     |\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 215      |\n",
      "|    total_timesteps    | 62000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.758   |\n",
      "|    explained_variance | 0.976    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -0.0387  |\n",
      "|    value_loss         | 0.0221   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 478      |\n",
      "|    ep_rew_mean        | 5.81     |\n",
      "| time/                 |          |\n",
      "|    fps                | 287      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 222      |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.69    |\n",
      "|    explained_variance | 0.643    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | -0.159   |\n",
      "|    value_loss         | 0.15     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 478      |\n",
      "|    ep_rew_mean        | 5.72     |\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 229      |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.46    |\n",
      "|    explained_variance | 0.115    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | 0.0254   |\n",
      "|    value_loss         | 0.194    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 479      |\n",
      "|    ep_rew_mean        | 5.75     |\n",
      "| time/                 |          |\n",
      "|    fps                | 288      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 235      |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.586   |\n",
      "|    explained_variance | 0.933    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | -0.12    |\n",
      "|    value_loss         | 0.0417   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 482      |\n",
      "|    ep_rew_mean        | 5.8      |\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 242      |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.669   |\n",
      "|    explained_variance | 0.953    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | -0.0956  |\n",
      "|    value_loss         | 0.0656   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 499      |\n",
      "|    ep_rew_mean        | 6.17     |\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 248      |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.767   |\n",
      "|    explained_variance | 0.39     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 0.136    |\n",
      "|    value_loss         | 0.26     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 492      |\n",
      "|    ep_rew_mean        | 6        |\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 255      |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.168   |\n",
      "|    explained_variance | -0.0793  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.167    |\n",
      "|    value_loss         | 0.226    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 494      |\n",
      "|    ep_rew_mean        | 6.11     |\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 262      |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.199   |\n",
      "|    explained_variance | 0.927    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.00376  |\n",
      "|    value_loss         | 0.0688   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 510      |\n",
      "|    ep_rew_mean        | 6.45     |\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 269      |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.564   |\n",
      "|    explained_variance | 0.842    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -0.104   |\n",
      "|    value_loss         | 0.12     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 515      |\n",
      "|    ep_rew_mean        | 6.49     |\n",
      "| time/                 |          |\n",
      "|    fps                | 289      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 276      |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.413   |\n",
      "|    explained_variance | 0.705    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -0.0968  |\n",
      "|    value_loss         | 0.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 517      |\n",
      "|    ep_rew_mean        | 6.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 282      |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.257   |\n",
      "|    explained_variance | 0.672    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | -0.0459  |\n",
      "|    value_loss         | 0.638    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 513      |\n",
      "|    ep_rew_mean        | 6.59     |\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 289      |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.418   |\n",
      "|    explained_variance | 0.852    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.157    |\n",
      "|    value_loss         | 0.151    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 513      |\n",
      "|    ep_rew_mean        | 6.57     |\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 296      |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.295   |\n",
      "|    explained_variance | 0.955    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 0.0435   |\n",
      "|    value_loss         | 0.126    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 509      |\n",
      "|    ep_rew_mean        | 6.49     |\n",
      "| time/                 |          |\n",
      "|    fps                | 290      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 302      |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.251   |\n",
      "|    explained_variance | 0.918    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | -0.0806  |\n",
      "|    value_loss         | 0.0922   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 514      |\n",
      "|    ep_rew_mean        | 6.56     |\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 308      |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0793  |\n",
      "|    explained_variance | 0.951    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.00171 |\n",
      "|    value_loss         | 0.0535   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 513      |\n",
      "|    ep_rew_mean        | 6.53     |\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 315      |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.405   |\n",
      "|    explained_variance | 0.887    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | -0.00217 |\n",
      "|    value_loss         | 0.0909   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 515      |\n",
      "|    ep_rew_mean        | 6.5      |\n",
      "| time/                 |          |\n",
      "|    fps                | 291      |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 322      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.294   |\n",
      "|    explained_variance | 0.416    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.0186  |\n",
      "|    value_loss         | 0.0636   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 520      |\n",
      "|    ep_rew_mean        | 6.62     |\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 328      |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.387   |\n",
      "|    explained_variance | 0.859    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.0211  |\n",
      "|    value_loss         | 0.0879   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 534      |\n",
      "|    ep_rew_mean        | 6.8      |\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 335      |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.343   |\n",
      "|    explained_variance | 0.566    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | -0.00515 |\n",
      "|    value_loss         | 0.121    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 531      |\n",
      "|    ep_rew_mean        | 6.7      |\n",
      "| time/                 |          |\n",
      "|    fps                | 292      |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 341      |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.549   |\n",
      "|    explained_variance | 0.916    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | -0.0884  |\n",
      "|    value_loss         | 0.0389   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7f8747347430>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3744682",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_path = os.path.join('Training','Saved Models','A2C_2M_model')\n",
    "model.save(a2c_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b10e010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env= make_atari_env('Breakout-v0',n_envs=1,seed=0)\n",
    "env= VecFrameStack(env,n_stack=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01ffdb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Observation spaces do not match: Box(0, 255, (4, 84, 84), uint8) != Box(0, 255, (4, 84, 84), uint8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgym\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m gym  \u001b[38;5;66;03m# patch 'gym' to point to 'gymnasium'\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mA2C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining/Saved Models/A2C_2M_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/stable_baselines3/common/base_class.py:717\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_env(env, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# Check if given env is valid\u001b[39;00m\n\u001b[0;32m--> 717\u001b[0m \u001b[43mcheck_for_correct_spaces\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservation_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;66;03m# Discard `_last_obs`, this will force the env to reset before training\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;66;03m# See issue https://github.com/DLR-RM/stable-baselines3/issues/597\u001b[39;00m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_reset \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/stable_baselines3/common/utils.py:232\u001b[0m, in \u001b[0;36mcheck_for_correct_spaces\u001b[0;34m(env, observation_space, action_space)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03mChecks that the environment has same spaces as provided ones. Used by BaseAlgorithm to check if\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mspaces match after loading the model with given env.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m:param action_space: Action space to check against\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_space \u001b[38;5;241m!=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space:\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObservation spaces do not match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action_space \u001b[38;5;241m!=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction spaces do not match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Observation spaces do not match: Box(0, 255, (4, 84, 84), uint8) != Box(0, 255, (4, 84, 84), uint8)"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from gymnasium import make\n",
    "\n",
    "# Dummy import for compatibility\n",
    "import sys\n",
    "import gymnasium as gym\n",
    "sys.modules[\"gym\"] = gym  # patch 'gym' to point to 'gymnasium'\n",
    "\n",
    "\n",
    "model = A2C.load('Training/Saved Models/A2C_2M_model', env=env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d80da7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(5.38), np.float64(2.4074052421642684))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model,env,n_eval_episodes=50,render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
